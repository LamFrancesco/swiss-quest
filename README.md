# SwissQuest ğŸ”ï¸

An AI-powered Swiss tourism activity search chatbot that uses dual NLP parsing approaches (TF-IDF + Embeddings vs LLM) to extract search filters from natural language queries.

## ğŸ› ï¸ Technologies

| Category | Technology |
|----------|------------|
| Frontend | React 18, TypeScript, Vite |
| Styling | Tailwind CSS, shadcn/ui |
| NLP (Client) | TF-IDF, Hugging Face Transformers (mxbai-embed-xsmall-v1) |
| NLP (Server) | Gemini 2.5 Flash via Lovable AI Gateway |
| API | MySwitzerland Tourism API |
| Backend | Supabase Edge Functions (Deno) |

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ components/                 # React UI components
â”‚   â”œâ”€â”€ ChatInterface.tsx       # Main chat UI with message handling
â”‚   â”œâ”€â”€ ChatMessage.tsx         # Individual message rendering
â”‚   â”œâ”€â”€ ActivityCard.tsx        # Activity result card display
â”‚   â”œâ”€â”€ ActivityDetail.tsx      # Detailed activity modal
â”‚   â”œâ”€â”€ Hero.tsx                # Hero banner component
â”‚   â””â”€â”€ ui/                     # shadcn/ui components (Button, Card, etc.)
â”‚
â”œâ”€â”€ lib/                        # Core business logic
â”‚   â”œâ”€â”€ nlp.ts                  # Entry point - routes to Fuzzy or LLM parser
â”‚   â”œâ”€â”€ nlpLLM.ts               # LLM parser client (calls Edge Function)
â”‚   â”œâ”€â”€ nlpSemantic.ts          # TF-IDF + Embeddings logic
â”‚   â”œâ”€â”€ tfidf.ts                # TF-IDF algorithm implementation
â”‚   â”œâ”€â”€ embeddings.ts           # HuggingFace transformer model loader
â”‚   â”œâ”€â”€ textMatching.ts         # Levenshtein distance & fuzzy metrics
â”‚   â”œâ”€â”€ metrics.ts              # Single query evaluation
â”‚   â”œâ”€â”€ metricsComparison.ts    # Fuzzy vs LLM comparison runner
â”‚   â”œâ”€â”€ metricsLiveAPI.ts       # Live API evaluation utilities
â”‚   â””â”€â”€ api.ts                  # MySwitzerland API client
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ goldStandardDataset.ts  # 15 test queries with expected results
â”‚
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Index.tsx               # Main application page
â”‚   â””â”€â”€ NotFound.tsx            # 404 page
â”‚
â”œâ”€â”€ hooks/                      # Custom React hooks
â””â”€â”€ integrations/
    â””â”€â”€ supabase/               # Supabase client configuration

supabase/
â””â”€â”€ functions/
    â””â”€â”€ parse-query-llm/        # Edge Function for LLM parsing
        â””â”€â”€ index.ts            # Gemini API call with prompt engineering
```

## ğŸš€ How to Run Locally

### Prerequisites
- Node.js 18+ 
- npm or bun

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd swissquest

# Install dependencies
npm install

# Start development server
npm run dev
```

The app will be available at `http://localhost:5173`

### Environment Variables

Create a `.env` file (optional for local development):

```env
VITE_SUPABASE_URL=<your-supabase-url>
VITE_SUPABASE_PUBLISHABLE_KEY=<your-supabase-key>
```

> **Note**: The Fuzzy Logic model works fully offline. LLM features require the Supabase Edge Function.

## ğŸ“¦ Deployment

### Build for Production

```bash
npm run build
```

This generates a `dist/` folder with static files.

### Deploy to Static Hosting

The built files can be deployed to any static hosting provider:

- **Vercel**: `vercel deploy`
- **Netlify**: Drag & drop `dist/` folder
- **GitHub Pages**: Use `gh-pages` package
- **Any web server**: Serve the `dist/` folder

### Backend Requirements

For LLM features to work in production, you need:
1. A Supabase project with Edge Functions enabled
2. The `parse-query-llm` function deployed
3. `LOVABLE_API_KEY` configured as a secret

## ğŸ§  Algorithm Overview

### Dual NLP Approach

SwissQuest uses two different approaches to parse natural language queries:

#### 1. Fuzzy Logic (TF-IDF + Embeddings)

**Runs client-side in the browser.**

```
User Query â†’ Tokenize â†’ Stem â†’ TF-IDF Vector â†’ Cosine Similarity â†’ Best Category Match
                                     â†“
                        OR: Embedding Model (mxbai-embed-xsmall-v1)
```

- **Speed**: ~50-200ms
- **Cost**: Free (runs locally)
- **Accuracy**: Good for explicit keywords
- **Deterministic**: Same input â†’ same output

#### 2. LLM (Gemini 2.5 Flash)

**Runs server-side via Edge Function.**

```
User Query â†’ Edge Function â†’ Gemini API â†’ Structured JSON â†’ Parsed Filters
```

- **Speed**: ~800-2000ms
- **Cost**: API usage fees
- **Accuracy**: Excellent for context and synonyms
- **Non-deterministic**: May vary slightly

### Fuzzy Metrics Evaluation

Both models are evaluated using **fuzzy metrics** (not binary thresholds):

| Metric | Formula |
|--------|---------|
| **Fuzzy Precision** | `Î£(all similarities) / total returned` |
| **Fuzzy Recall** | `Î£(best match per expected) / total expected` |
| **F1-Score** | `2 Ã— (P Ã— R) / (P + R)` |

Similarity is calculated using **Levenshtein Distance**:

```
similarity = 1 - (edit_distance / max_length)
```

## â˜ï¸ Cloud Dependencies

This project is hosted on **Lovable Cloud**, which provides:

| Service | Purpose |
|---------|---------|
| **Supabase Edge Functions** | Serverless backend for LLM parsing |
| **Lovable AI Gateway** | Access to Gemini 2.5 Flash without API key management |
| **Auto-configured secrets** | `LOVABLE_API_KEY` is pre-configured |

### Gemini 2.5 Flash

The LLM parser uses **Google Gemini 2.5 Flash** via the Lovable AI Gateway:

- **Endpoint**: `https://ai.gateway.lovable.dev/v1/chat/completions`
- **Model**: `google/gemini-2.5-flash`
- **Features**: Fast inference, good accuracy, structured JSON output

### MySwitzerland API

Activity data is fetched from the official MySwitzerland Tourism API:

- **Endpoint**: `https://www.myswitzerland.com/api/search`
- **Data**: Swiss tourism activities with filters (category, canton, duration, etc.)

## ğŸ“Š Model Comparison

Click "Fuzzy vs LLM" in the app to run a comparison against 15 gold standard queries:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPARISON RESULTS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Metric              â”‚ Fuzzy Logic    â”‚ LLM (Gemini)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Avg Latency         â”‚ ~100ms         â”‚ ~1200ms              â”‚
â”‚ Avg Precision       â”‚ 0.45           â”‚ 0.52                 â”‚
â”‚ Avg Recall          â”‚ 0.38           â”‚ 0.48                 â”‚
â”‚ Avg F1-Score        â”‚ 0.41           â”‚ 0.50                 â”‚
â”‚ Filter Accuracy     â”‚ 0.72           â”‚ 0.85                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Commit changes: `git commit -m 'Add my feature'`
4. Push to branch: `git push origin feature/my-feature`
5. Open a Pull Request
